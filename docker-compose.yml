services:
  # ─── Next.js Frontend + API ──────────────────────────────────
  web:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - DATABASE_URL=file:/app/data/dev.db
      - BETTER_AUTH_SECRET=${BETTER_AUTH_SECRET}
      - BETTER_AUTH_URL=http://localhost:3000
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - AI_PROVIDER=${AI_PROVIDER:-openai}
      - AI_MODEL=${AI_MODEL:-gpt-4o}
      - RAG_SERVER_URL=http://rag:8020
      - RAG_API_KEY=${RAG_API_KEY}
    depends_on:
      rag:
        condition: service_healthy
    volumes:
      - db-data:/app/data
      - uploads:/app/.uploads
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    restart: unless-stopped

  # ─── LightRAG + RAG-Anything Server ─────────────────────────
  rag:
    build:
      context: ./rag-server
      dockerfile: Dockerfile
    ports:
      - "8020:8020"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_BASE_URL=${OPENAI_BASE_URL:-https://api.openai.com/v1}
      - LLM_MODEL=${AI_MODEL:-gpt-4o}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL:-text-embedding-3-small}
      - RAG_API_KEY=${RAG_API_KEY}
    volumes:
      - rag-data:/app/rag_storage
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:8020/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    restart: unless-stopped

volumes:
  db-data:
  rag-data:
  uploads:
