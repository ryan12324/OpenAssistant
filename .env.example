# Better Auth
BETTER_AUTH_SECRET=your-secret-key-here  # generate with: openssl rand -base64 32
BETTER_AUTH_URL=http://localhost:3000

# Database
DATABASE_URL="file:./dev.db"

# AI Provider Configuration
# Set AI_PROVIDER to switch the default model provider.
# Supported: openai, anthropic, google, mistral, xai, deepseek, openrouter,
#            perplexity, ollama, lmstudio, minimax, glm, huggingface, vercel
AI_PROVIDER=openai
AI_MODEL=gpt-4o

# You can also use "provider/model" format in AI_MODEL:
#   AI_MODEL=anthropic/claude-sonnet-4-5-20250929
#   AI_MODEL=google/gemini-2.5-pro
#   AI_MODEL=deepseek/deepseek-chat

# Provider API Keys (set the ones you want to use)
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
GOOGLE_AI_API_KEY=
MISTRAL_API_KEY=
XAI_API_KEY=
DEEPSEEK_API_KEY=
OPENROUTER_API_KEY=
PERPLEXITY_API_KEY=
MINIMAX_API_KEY=
GLM_API_KEY=
HUGGINGFACE_API_KEY=
VERCEL_AI_GATEWAY_KEY=

# Local Model Providers (no API key needed)
# OLLAMA_BASE_URL=http://localhost:11434
# LMSTUDIO_BASE_URL=http://localhost:1234

# LightRAG Server
# AI_PROVIDER, AI_MODEL, and API keys above are shared with the RAG server.
RAG_SERVER_URL=http://localhost:8020
RAG_API_KEY=your-rag-api-key

# Optional: separate embedding config (defaults to LLM provider settings)
# EMBEDDING_MODEL=text-embedding-3-small
# EMBEDDING_API_KEY=
# EMBEDDING_BASE_URL=

# Optional: GitHub OAuth
GITHUB_CLIENT_ID=
GITHUB_CLIENT_SECRET=

# Optional: Google OAuth
GOOGLE_CLIENT_ID=
GOOGLE_CLIENT_SECRET=
